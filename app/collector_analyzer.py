import asyncio
import csv
import logging
import os
from datetime import datetime, timedelta

from sqlalchemy import select, func
from sqlalchemy.ext.asyncio import AsyncSession

from app.constants.settings import OUTDATED_THRESHOLD, EXPORT_INTERVAL_SECONDS
from app.db import SessionLocal
from app.models import AnalyzerOddsParsed
from app.constants.csv_columns import CSV_ANALYZER_COLUMNS
from app.constants.paths import EXPORT_ANALYZER_DIR
from app.utils import format_filename


logger = logging.getLogger(__name__)


async def collect_and_export_old_analyzer_data():
    """
    –ù–∞—Ö–æ–¥–∏—Ç –∏ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –º–∞—Ç—á–∏ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞, –∑–∞—Ç–µ–º —É–¥–∞–ª—è–µ—Ç –∏—Ö –∏–∑ –±–∞–∑—ã.
    """
    now = datetime.utcnow()
    outdated_time = now - timedelta(hours=OUTDATED_THRESHOLD)

    async with SessionLocal() as session:
        match_keys = await find_stale_analyzer_matches(session, outdated_time)

        for match_id, outcome in match_keys:
            await export_and_delete_analyzer_match(session, match_id, outcome)


async def find_stale_analyzer_matches(
        session: AsyncSession,
        outdated_time: datetime
) -> list[tuple[int, str]]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø–∞—Ä (match_id_pinnacle, outcome), —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –ø–æ –≤—Ä–µ–º–µ–Ω–∏.
    """
    subquery = (
        select(
            AnalyzerOddsParsed.match_id_pinnacle,
            AnalyzerOddsParsed.outcome,
            func.max(AnalyzerOddsParsed.created_at).label('max_created_at')
        )
        .group_by(AnalyzerOddsParsed.match_id_pinnacle, AnalyzerOddsParsed.outcome)
        .subquery()
    )

    result = await session.execute(
        select(subquery.c.match_id_pinnacle, subquery.c.outcome)
        .where(subquery.c.max_created_at < outdated_time)
    )

    match_keys = result.all()
    logger.info(f'üîç –ù–∞–π–¥–µ–Ω–æ {len(match_keys)} —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –º–∞—Ç—á–µ–π-–∞–Ω–∞–ª–∏–∑–æ–≤')
    return match_keys


async def export_and_delete_analyzer_match(
        session: AsyncSession,
        match_id: int,
        outcome: str
):
    """
    –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø–æ –ø–∞—Ä–µ (match_id, outcome) –≤ CSV –∏ —É–¥–∞–ª—è–µ—Ç –∏—Ö –∏–∑ –±–∞–∑—ã.
    """
    logger.info(f'üì¶ –≠–∫—Å–ø–æ—Ä—Ç –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞: match={match_id}, outcome={outcome}')

    result = await session.stream(
        select(AnalyzerOddsParsed).where(
            AnalyzerOddsParsed.match_id_pinnacle == match_id,
            AnalyzerOddsParsed.outcome == outcome
        )
    )

    rows = []
    async for row in result.scalars():
        rows.append(row)

    if not rows:
        logger.warning(f'‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è match={match_id}, outcome={outcome}')
        return

    created_at_sample = rows[0].created_at
    home = rows[0].home_team
    away = rows[0].away_team
    sport = rows[0].sport_name
    file_name = format_filename(match_id, created_at_sample, home, away, sport, outcome)
    file_path = os.path.join(EXPORT_ANALYZER_DIR, file_name)

    with open(file_path, mode='w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=CSV_ANALYZER_COLUMNS)
        writer.writeheader()
        for row in rows:
            writer.writerow({
                'createdAt': row.raw_created_at,
                'sportName': row.sport_name,
                'matchId_pinnacle': row.match_id_pinnacle,
                'matchId_lobbet': row.match_id_lobbet,
                'homeName': row.home_team,
                'awayName': row.away_team,
                'homeScore': row.home_score,
                'awayScore': row.away_score,
                'league_pinnacle': row.league_pinnacle,
                'league_lobbet': row.league_lobbet,
                'bookmaker_1': 'Pinnacle',
                'bookmaker_2': 'Lobbet',
                'market': row.market_type,
                'outcome': row.outcome,
                'value_pinnacle': row.value_pinnacle,
                'value_lobbet': row.value_lobbet,
                'roi': row.roi,
                'margin': row.margin,
                'marketType': row.market_type,
            })

    await session.execute(
        AnalyzerOddsParsed.__table__.delete().where(
            AnalyzerOddsParsed.match_id_pinnacle == match_id,
            AnalyzerOddsParsed.outcome == outcome
        )
    )
    await session.commit()
    logger.info(f'‚úÖ –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –∏ —É–¥–∞–ª–µ–Ω–æ: match={match_id}, outcome={outcome}')


async def run_analyzer_collector_loop():
    """
    –¶–∏–∫–ª–∏—á–Ω–æ –∑–∞–ø—É—Å–∫–∞–µ—Ç —Å–±–æ—Ä —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –º–∞—Ç—á–µ–π —Å –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º EXPORT_INTERVAL_SECONDS.
    """
    while True:
        await collect_and_export_old_analyzer_data()
        await asyncio.sleep(EXPORT_INTERVAL_SECONDS)
